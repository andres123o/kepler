# üöÄ Mejoras Planeadas para V1 - Agente Orquestador Kepler

## üìã Contexto

Este documento describe las mejoras que se implementar√°n en la **versi√≥n 1** del agente. Actualmente estamos en **v0 (MVP)** y estas optimizaciones est√°n planificadas para reducir costos y mejorar eficiencia cuando escalemos.

---

## üéØ Problema Actual (v0)

En v0, el agente:
- ‚úÖ Recibe **TODOS** los contextos de negocio de la organizaci√≥n
- ‚úÖ El agente (GPT-4) filtra y usa solo los relevantes
- ‚ö†Ô∏è **Desventaja:** Gasta tokens innecesariamente enviando contextos irrelevantes

Esto es **aceptable para MVP y primeros 3 clientes**, pero necesita optimizaci√≥n para escalar.

---

## üí° Mejoras Planeadas para V1

### 1. Selecci√≥n Inteligente de Contextos (Opci√≥n C + Embeddings)

#### Objetivo
Reducir tokens enviados a GPT-4 seleccionando solo los contextos relevantes antes de construir el prompt.

#### Implementaci√≥n Propuesta

**Opci√≥n C: Selecci√≥n por Metadata/Nombre + Embeddings**

**Paso 1: Clasificaci√≥n por Metadata/Nombre (R√°pido, sin costo)**
- Si un contexto tiene `metadata.category` o palabras clave en el nombre, clasificarlo autom√°ticamente
- Ejemplo:
  - "Misi√≥n" ‚Üí `category: "general"`
  - "Objetivos Q1 2024" ‚Üí `category: "objetivos"`
  - "Funnel Onboarding" ‚Üí `category: "onboarding"`

**Paso 2: Embeddings para Selecci√≥n Sem√°ntica (Preciso, bajo costo)**
- Generar embedding del patr√≥n detectado (despu√©s del clustering de datos)
- Generar embeddings de todos los contextos de negocio
- Calcular similitud coseno
- Seleccionar top 3-5 contextos m√°s similares

**Paso 3: Combinaci√≥n**
- Usar Opci√≥n C para pre-filtrar por categor√≠a obvia
- Usar embeddings para casos donde no hay categor√≠a clara
- Enviar solo contextos seleccionados a GPT-4

#### Ventajas
- ‚úÖ Reduce tokens significativamente (solo 2-3 contextos vs todos)
- ‚úÖ M√°s preciso que solo keywords
- ‚úÖ Embeddings son baratos ($0.02-0.13 por 1M tokens)
- ‚úÖ Escalable a organizaciones con muchos contextos

#### Costo Estimado
- Embeddings: ~$0.0001-0.001 por an√°lisis (10-50 contextos)
- Ahorro en GPT-4: ~$0.05-0.20 por an√°lisis (menos tokens)
- **ROI Positivo:** Ahorra m√°s de lo que cuesta

#### Archivos a Crear/Modificar
- `app/agents/kepler/context-selector.ts` (nuevo)
- Modificar `context-builder.ts` para usar selector

---

### 2. Embeddings + Clustering para Datos de Fuentes

#### Objetivo
Agrupar datos similares (tickets, reviews, comentarios) antes de enviar a GPT-4 para:
- Reducir tokens enviados
- Mejor identificaci√≥n de patrones
- An√°lisis m√°s robusto

#### Implementaci√≥n Propuesta

**Flujo:**

```
Datos Recopilados (Tickets, Reviews, etc.)
    ‚Üì
Generar Embeddings (text-embedding-3-small)
    ‚Üì
Clustering (K-means o Similaridad)
    ‚Üì
Seleccionar Top Clusters (por tama√±o + densidad)
    ‚Üì
Representar cada cluster (centroide + ejemplos)
    ‚Üì
Enviar clusters resumidos a GPT-4
```

#### Detalles T√©cnicos

**1. Generaci√≥n de Embeddings:**
- Modelo: `text-embedding-3-small` (suficiente para MVP, m√°s barato)
- Batch: Procesar en lotes de 100 para eficiencia
- Cach√©: Guardar embeddings en BD para evitar regenerar

**2. Clustering:**
- **Opci√≥n Simple (MVP):** Similaridad coseno + agrupaci√≥n por umbral (ej: >0.75)
- **Opci√≥n Avanzada (V1):** K-means con n√∫mero √≥ptimo de clusters (elbow method)
- Tama√±o m√≠nimo de cluster: 3 elementos (evitar ruido)

**3. Representaci√≥n de Clusters:**
- Centroide del cluster (embedding promedio)
- 3-5 ejemplos representativos (m√°s cercanos al centroide)
- Estad√≠sticas: tama√±o, score promedio (si aplica), fechas

**4. Priorizaci√≥n:**
- Volumen √ó Riesgo estimado
- Clusters m√°s grandes primero
- Clusters con scores bajos (NPS/CSAT/Reviews) primero

#### Ventajas
- ‚úÖ Detecta patrones sem√°nticos reales (no keywords)
- ‚úÖ Reduce tokens: En lugar de 100 tickets, enviar 5-10 clusters resumidos
- ‚úÖ Mejor identificaci√≥n del P0 (clusters ya agrupados)
- ‚úÖ Escalable a miles de datos

#### Desventajas
- ‚ö†Ô∏è Requiere implementaci√≥n de clustering
- ‚ö†Ô∏è Latencia adicional (generaci√≥n de embeddings)
- ‚ö†Ô∏è Necesita almacenar embeddings (BD o cach√©)

#### Costo Estimado
Para 1000 tickets/reviews:
- Embeddings: ~$0.001-0.005
- GPT-4 (con datos agrupados): ~$0.10-0.30
- **Total:** ~$0.10-0.31 por an√°lisis

**Sin clustering:** Enviar todo a GPT-4 podr√≠a costar $1-5 por an√°lisis.

**Ahorro:** ~70-90% en costos de GPT-4

#### Archivos a Crear
- `app/agents/kepler/semantic-analyzer.ts` (nuevo)
  - `generateEmbeddings()`
  - `clusterData()`
  - `prioritizeClusters()`
  - `representCluster()`
- Modificar `agent.ts` para usar analizador sem√°ntico
- Crear tabla en BD para cachear embeddings (opcional para V1)

---

## üìä Comparaci√≥n v0 vs v1

| Aspecto | v0 (MVP) | v1 (Planeado) |
|---------|----------|---------------|
| Contextos enviados | Todos | Top 3-5 relevantes |
| Datos enviados | Todos (limitados a 30) | Clusters resumidos |
| Tokens promedio | ~3000-5000 | ~1000-2000 |
| Costo por an√°lisis | ~$0.30-0.80 | ~$0.10-0.35 |
| Latencia | ~5-10s | ~8-15s (+ embeddings) |
| Precisi√≥n | Buena | Mejor (clustering previo) |
| Escalabilidad | Limitada | Excelente |

---

## üõ†Ô∏è Plan de Implementaci√≥n V1

### Fase 1: Embeddings + Clustering para Datos (Prioridad Alta)
**Estimado:** 2-3 d√≠as

1. Crear `semantic-analyzer.ts`
2. Implementar generaci√≥n de embeddings
3. Implementar clustering simple (similaridad coseno)
4. Integrar con `agent.ts`
5. Testear con datos reales

**Beneficio:** Reducci√≥n de costos inmediata

### Fase 2: Selecci√≥n Inteligente de Contextos (Prioridad Media)
**Estimado:** 1-2 d√≠as

1. Crear `context-selector.ts`
2. Implementar clasificaci√≥n por metadata/nombre
3. Implementar selecci√≥n por embeddings
4. Integrar con `context-builder.ts`
5. Testear con m√∫ltiples organizaciones

**Beneficio:** Reducci√≥n adicional de tokens

### Fase 3: Optimizaciones y Cach√© (Prioridad Baja)
**Estimado:** 1 d√≠a

1. Cachear embeddings en BD
2. Optimizar batch processing
3. Agregar m√©tricas y logging
4. Documentaci√≥n

**Beneficio:** Mejor rendimiento y monitoreo

---

## üìö Recursos y Referencias

### Librer√≠as Necesarias
- `openai` (ya instalado) - Para embeddings
- `ml-distance` o `ml-matrix` - Para clustering (opcional, podemos hacer simple)
- O implementaci√≥n simple de similaridad coseno

### Documentaci√≥n OpenAI
- [Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [text-embedding-3-small](https://platform.openai.com/docs/models/embeddings)

### Algoritmos de Clustering
- Similaridad Coseno (simple, r√°pido)
- K-means (m√°s preciso, requiere n√∫mero de clusters)
- DBSCAN (auto-detecta n√∫mero de clusters)

---

## ‚úÖ Criterios de √âxito V1

- [ ] Reducci√≥n de tokens del 50%+
- [ ] Reducci√≥n de costos del 40%+
- [ ] Precisi√≥n igual o mejor que v0
- [ ] Latencia < 20s (aceptable con embeddings)
- [ ] Funciona con 100+ tickets/reviews
- [ ] Funciona con 10+ contextos de negocio

---

## üéØ Conclusi√≥n

Estas mejoras son **necesarias para escalar** pero **no cr√≠ticas para MVP**. 

**v0 es suficiente para:**
- Primeros 3-10 clientes
- Validar el producto
- Obtener feedback real

**v1 ser√° necesario cuando:**
- Tengamos 10+ clientes activos
- Los costos se vuelvan significativos
- Necesitemos escalar a m√°s datos

**Prioridad de implementaci√≥n:**
1. Embeddings + Clustering para datos (mayor impacto en costos)
2. Selecci√≥n inteligente de contextos (optimizaci√≥n adicional)

